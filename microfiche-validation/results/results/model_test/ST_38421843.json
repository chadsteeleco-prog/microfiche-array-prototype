{
  "id": "ST_38421843",
  "summary": "However, these models face significant\n        challenges with memory efficiency and context length ...",
  "confidence": 1.0,
  "full_text": "However, these models face significant\n        challenges with memory efficiency and context length limitations The quadratic\n        scaling of attention mechanisms creates bottlenecks for processing long documents",
  "metadata": {
    "sentence_count": 2,
    "original_length": 215,
    "compressed_length": 103,
    "compression_ratio": 0.5209302325581395
  }
}