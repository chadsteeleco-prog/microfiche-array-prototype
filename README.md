# microfiche-array-prototype
**Hierarchical tokenization with semantic compression for efficient LLM inference**
